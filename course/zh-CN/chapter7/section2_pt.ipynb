{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:44.059912Z",
     "start_time": "2025-04-14T02:45:44.057723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "id": "9b547ceb9cabe022",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:47.991978Z",
     "start_time": "2025-04-14T02:45:44.125275Z"
    }
   },
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:48.093147Z",
     "start_time": "2025-04-14T02:45:48.090373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "distilbert_num_parameters = model.num_parameters() / 1_000_000\n",
    "print(f\"'>>> DistilBERT number of parameters: {round(distilbert_num_parameters)}M'\")\n",
    "print(f\"'>>> BERT number of parameters: 110M'\")"
   ],
   "id": "5324edbc0498deb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> DistilBERT number of parameters: 67M'\n",
      "'>>> BERT number of parameters: 110M'\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:48.164103Z",
     "start_time": "2025-04-14T02:45:48.162295Z"
    }
   },
   "cell_type": "code",
   "source": "text = \"This is a great [MASK].\"",
   "id": "d0aad9eaad20332a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:48.571125Z",
     "start_time": "2025-04-14T02:45:48.227251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ],
   "id": "f233ed30cc2fb185",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:48.780728Z",
     "start_time": "2025-04-14T02:45:48.725381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "token_logits = model(**inputs).logits"
   ],
   "id": "a227776433fae55a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:48.853549Z",
     "start_time": "2025-04-14T02:45:48.850528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()"
   ],
   "id": "a1bc68695d2c6afc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:48.920446Z",
     "start_time": "2025-04-14T02:45:48.918070Z"
    }
   },
   "cell_type": "code",
   "source": "print(mask_token_index)",
   "id": "da045bfc75e0b4f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:49.035822Z",
     "start_time": "2025-04-14T02:45:49.032547Z"
    }
   },
   "cell_type": "code",
   "source": "print(token_logits)",
   "id": "e9e1ee357b324012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -5.5882,  -5.5868,  -5.5958,  ...,  -4.9448,  -4.8174,  -2.9905],\n",
      "         [-11.9031, -11.8872, -12.0623,  ..., -10.9570, -10.6464,  -8.6324],\n",
      "         [-11.9604, -12.1520, -12.1279,  ..., -10.0218,  -8.6074,  -8.0971],\n",
      "         ...,\n",
      "         [ -4.8228,  -4.6268,  -5.1041,  ...,  -4.2771,  -5.0184,  -3.9428],\n",
      "         [-11.2945, -11.2388, -11.3857,  ...,  -9.2063,  -9.3411,  -6.1505],\n",
      "         [ -9.5213,  -9.4632,  -9.5022,  ...,  -8.6561,  -8.4908,  -4.6903]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:49.144860Z",
     "start_time": "2025-04-14T02:45:49.142437Z"
    }
   },
   "cell_type": "code",
   "source": "print(mask_token_logits)",
   "id": "a35ba930bb893f53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4.8228, -4.6268, -5.1041,  ..., -4.2771, -5.0184, -3.9428]],\n",
      "       grad_fn=<IndexBackward0>)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:49.259677Z",
     "start_time": "2025-04-14T02:45:49.257281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for token in top_5_tokens:\n",
    "    print(f\"'>>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}'\")"
   ],
   "id": "b1b84babb0e9bd28",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> This is a great deal.'\n",
      "'>>> This is a great success.'\n",
      "'>>> This is a great adventure.'\n",
      "'>>> This is a great idea.'\n",
      "'>>> This is a great feat.'\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:58.340754Z",
     "start_time": "2025-04-14T02:45:49.330359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "imdb_dataset"
   ],
   "id": "b4764a775fb44843",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:58.413082Z",
     "start_time": "2025-04-14T02:45:58.407941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sample = imdb_dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\"\\n'>>> Review: {row['text']}'\")\n",
    "    print(f\"'>>> Label: {row['label']}'\")"
   ],
   "id": "dc04dd26bef91b98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> Review: There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...'\n",
      "'>>> Label: 1'\n",
      "\n",
      "'>>> Review: This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The movie starts of with a scene where Hank sings a song with a bunch of kids called \"when you stub your toe on the moon\" It reminds me of Sinatra's song High Hopes, it is fun and inspirational. The Music is great throughout and my favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie.'\n",
      "'>>> Label: 1'\n",
      "\n",
      "'>>> Review: George P. Cosmatos' \"Rambo: First Blood Part II\" is pure wish-fulfillment. The United States clearly didn't win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn't appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \"We Were Soldiers\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.'\n",
      "'>>> Label: 0'\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:58.523796Z",
     "start_time": "2025-04-14T02:45:58.522303Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fdc8da249ddbe2ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:58.602373Z",
     "start_time": "2025-04-14T02:45:58.597188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unsupervised_sample = imdb_dataset[\"unsupervised\"].shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in unsupervised_sample:\n",
    "    print(f\"\\n'>>> Review: {row['text']}'\")\n",
    "    print(f\"'>>> Label: {row['label']}'\")"
   ],
   "id": "5e11fbcc27a3598c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> Review: If you've seen the classic Roger Corman version starring Vincent Price it's hard to put it out of your head, but you probably should do because this one is totally different. Subtlety has been abandoned in favour of gross-out horror - nudity, gore and all-round unpleasantness. OK it's ridiculous, trashy, sensationalised and historically dubious (did any members of the Inquisition really wear horn-rimmed glasses?), but despite all this it is strangely compelling. I literally couldn't tear myself away from the screen until the end of the movie. If there's a bigger compliment you can pay to a film I don't know what it is.'\n",
      "'>>> Label: -1'\n",
      "\n",
      "'>>> Review: For me, this was the most moving film of the decade. Samira Makhmalbaf shows pure bravery and vision in the making. She has an intelligence and gift for speaking to the people, regardless of their nationality or beliefs. I am inspired and touched by her humanity and can only hope that she has touched many people the same way. Her message in this film is strong, simple and pure. The human soul can survive the most unheard of cruelties and repression, yet still have the capability to hope and dream even the biggest dreams. Under the most incredible circumstances, the most unexpected people rise up to be heroes. This young girl who has recently regained her voice, yet is still afraid to use her new found freedom, is our hero. She daydreams of becoming president of war torn Afghanistan, the only vision of power that she can imagine that could truly change her current situation. We catch a glimpse of her spirit while witnessing her hardships. In the end, we are left with hope, hope that when her young voice does eventually speak out, it speaks loud and clear for all to hear- sounding a message that transcends borders, nationality and religion. The true epitome of the phoenix rising from the ashes. Hats off to the simple tale of the complex truth.'\n",
      "'>>> Label: -1'\n",
      "\n",
      "'>>> Review: There really isn't much to say about this \"film\". It has the odd smile or chuckle moment, but on the whole it's bland, predictable and generally pretty dull.<br /><br />The only reason I gave it three out of ten was for the annoyingly catchy jingle (which I hope I will forget soon....please God!). Otherwise its junk. Or mostly junk, interspersed with adverts for Smirnoff Ice.<br /><br />The lead characters give OK performances, but they really don't have anything much to work with.<br /><br />Best advice: Avoid it like a dentist's appointment. Or better yet, make a dentist's appointment instead of watching it.'\n",
      "'>>> Label: -1'\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:58.714453Z",
     "start_time": "2025-04-14T02:45:58.712248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result"
   ],
   "id": "1ded4c5ad010ca56",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:58.792259Z",
     "start_time": "2025-04-14T02:45:58.772240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_datasets = imdb_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\", \"label\"]\n",
    ")\n",
    "tokenized_datasets"
   ],
   "id": "dcf5e5d924e30ea9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:58.898160Z",
     "start_time": "2025-04-14T02:45:58.895688Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.model_max_length",
   "id": "a700ec7e5ea507f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:59.024298Z",
     "start_time": "2025-04-14T02:45:59.022527Z"
    }
   },
   "cell_type": "code",
   "source": "chunk_size = 512",
   "id": "45fb2864700247c6",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:59.085854Z",
     "start_time": "2025-04-14T02:45:59.082608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ],
   "id": "41d044a594ada6d9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 363'\n",
      "'>>> Review 1 length: 304'\n",
      "'>>> Review 2 length: 133'\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:59.164560Z",
     "start_time": "2025-04-14T02:45:59.162250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "concatenated_examples = {\n",
    "    k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()\n",
    "}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'>>> Concatenated reviews length: {total_length}'\")"
   ],
   "id": "33e55046f854705f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Concatenated reviews length: 800'\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:59.237616Z",
     "start_time": "2025-04-14T02:45:59.235202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunks = {\n",
    "    k: [t[i: i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ],
   "id": "7b8126408f402629",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Chunk length: 512'\n",
      "'>>> Chunk length: 288'\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:45:59.320023Z",
     "start_time": "2025-04-14T02:45:59.317391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def group_texts(examples):\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    result = {\n",
    "        k: [t[i: i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ],
   "id": "83b50fd336f9d83",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:05.314654Z",
     "start_time": "2025-04-14T02:45:59.382212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ],
   "id": "aa631dd893c71a05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e37bf0aec1f48c8867a561bdedd0c06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 15313\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 14966\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 30721\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:05.433232Z",
     "start_time": "2025-04-14T02:47:05.427122Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])",
   "id": "aab2b9f53f6e47f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the brown bunny, in which we \\' re treated to the site of vincent gallo \\' s throbbing johnson, but not a trace of pink visible on chloe sevigny. before crying ( or implying ) \" double - standard \" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women : there are no genitals on display when actresses appears nude, and the same cannot be said for a man. in fact, you generally won \\' t see female genitals in an american film in anything short of porn or explicit erotica. this alleged double - standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women \\' s bodies. [SEP] [CLS] if only to avoid making this type of film in the future. this film is interesting as an experiment but tells no cogent story. < br / > < br / > one might feel virtuous for sitting thru it because it touches on so many important issues but it does so without any discernable motive. the viewer comes away with no new perspectives ( unless one comes up with one while one \\' s mind wanders, as it will invariably do during this pointless film ). < br / > < br / > one might better spend one \\' s time staring out a window at a tree growing. < br / > < br / > [SEP] [CLS] this film was probably inspired by godard \\' s masculin, feminin and i urge you to see that film instead. < br / > < br / > the film has two strong elements and those are, ( 1 ) the realistic acting ( 2 ) the impressive, undeservedly good, photo. apart from that, what strikes me most is the endless stream of silliness. lena nyman has to be most annoying actress in the world. she acts so stupid and with all the nudity in this film,... it \\' s unattractive. comparing to godard \\' s film, intellectuality has been replaced with stupidity. without going too far on this subject, i would say that follows from the difference in ideals between the french and the swedish society. < br / > < br / > a movie of its time, and place. 2 / 10. [SEP] [CLS] oh, brother... after hearing about this ridiculous film for umpteen years all i can think of is that old peggy lee song.. < br / > < br / >'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:05.541832Z",
     "start_time": "2025-04-14T02:47:05.530218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)"
   ],
   "id": "80f5dbd7fb91f294",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:05.650786Z",
     "start_time": "2025-04-14T02:47:05.642285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ],
   "id": "705c83ed8041335f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] i rented i am [MASK] - yellow from overgrown video [MASK] because of all the [MASK] that [MASK] it when it was vegetable released in 1967. i also [MASK] that at first it was seized by u. s. customs if it ever tried to enter this country, therefore being [MASK] fan of films considered \" controversial [MASK] [MASK] really had [MASK] see this for myself. < devils / > < br / > the plot is centered around a young [MASK] drama student named lena [MASK] wants to learn everything she can about life [MASK] in particular she wants to focus her [MASK]s [MASK] making some sort of documentary [MASK] [MASK] the average swede thought about certain [MASK] issues such as the vietnam war and race issues [MASK] the united states. in [MASK] asking politicians and ordinary [MASK]izens of stockholm about their opinions on politics, she has sex with [MASK] drama teacher, classmates, and married men. spells br / > < br / > [MASK] kills me about i am [MASK] - yellow is that 40 years [MASK], this [MASK] considered pornographic. really, the sex and nudity scenes are few and far between, even [MASK] it ' s not shot [MASK] some cheaply made porno. while my countrymen mind find it shocking, in reality sex and nu [MASK] are a [MASK] staple in swedish cinema. even ingmar bergman, arguably [MASK] answer to good old boy john [MASK], had sex scenes in [MASK] films. < [MASK] [MASK] > < br / > [MASK] do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just [MASK] [MASK] [MASK] and make money to be shown in pornographic theaters in america. i am curious - yellow is a good film for anyone wanting to study the meat and potatoes ( no pun intended ) of swedish cinema. but really, [MASK] film doesn ' t have much of a plot. [SEP] [CLS] \" i am curious : yellow \" is a risible and pretentious steaming [MASK]. it doesn ' t matter what one ' [MASK] political views are because this film [MASK] hardly be taken seriously on any level. as for the claim that frontal male nudity is an automatic [MASK] - 17, that isn ' t true. i ' ve seen [MASK] - rated films with male nudity. granted [MASK] they only offer some fleeting views, [MASK] [MASK] are the r - rated films with gaping vu [MASK]s and flapping [unused804]ia?坂, [MASK] they don ' t exist. the [MASK] [MASK] for those crappy cable shows : schlongs swinging [MASK] the breeze but not a clitoris [MASK] sight. and those pretentious indie movies [MASK]'\n",
      "\n",
      "'>>> the brown bunny, in which we ' re allison to the site of vincent gallo ' s throbbing johnson, but not a [MASK] [MASK] pink visible on [MASK] se [MASK]gny. before [MASK] ( or implying ) \" double - standard \" in conceptual of nudity, the古 ob [MASK] [MASK] venezuela take into account one unavoidably obvious anatomical difference between men and women : there are no gen [MASK]s on display when actresses appears nude [MASK] and the ब cannot be said for a man. in fact, you generally [MASK] ' t see female loaditals in良 american film in anything short [MASK] porn or explicit erotica. this alleged double [MASK] standard is less a [MASK] standard than [MASK] admittedly de [MASK] ability to come to terms culturally with [MASK] insides of women ' s bodies. [SEP] [CLS] if only to avoid making this type of film in the future. this film [MASK] [MASK] as an experiment but [MASK] no cogent story. < br / > < br / > one [MASK] feel virtuous for sitting thru it because it touches on so many important issues but it does so without any discern [MASK] motive. the viewer comes away [MASK] no new perspectives ( unless one comes up with one while one ' [MASK] ned wander [MASK], as [MASK] will [MASK] do during this pointless film ) [MASK] < br / [MASK] < br / > one might better spend [MASK] ' [MASK] time staring [MASK] [MASK] window at a tree growing. < br / > < br / [MASK] [SEP] [CLS] this [MASK] was probably inspired [MASK] godard ' s mas [MASK]lin, feminin and [MASK] urge you to [MASK] that film instead. < br / > < br / > the film has two strong elements and those are, ( crack ) the realistic acting ( 2 ) the impressive, undese [MASK]vedly good, photo. [MASK] from that, what strikes me most is the [MASK] stream [MASK] silliness. lena nyman has to be most annoying actress in the world. she [MASK] so stupid and with all [MASK] nudity [MASK] this film,. [MASK] [MASK] it ' s [MASK]tt [MASK]. comparing to godard [MASK] s film, intellectuality has been replaced with stupidity. without going [MASK] far [MASK] this subject, i would sayleen follows [MASK] the difference in ideals between the french [MASK] the swedish society. < br / > < br / > a apr of its time, and place. 2 / 10. [SEP] [CLS] oh [MASK] brother... after hearing about [MASK] ridiculous film for [MASK]pt [MASK] years all i can think of is that [MASK] peggy [MASK] song.. < br / > < [MASK] / >'\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:05.764208Z",
     "start_time": "2025-04-14T02:47:05.762323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "\n",
    "from transformers import default_data_collator\n",
    "\n",
    "wwm_probability = 0.2"
   ],
   "id": "15c5272755356bf8",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:05.894613Z",
     "start_time": "2025-04-14T02:47:05.891451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def whole_word_masking_data_collator(features):\n",
    "    for feature in features:\n",
    "        word_ids = feature.pop(\"word_ids\")\n",
    "\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        labels = feature[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        feature[\"labels\"] = new_labels\n",
    "    return default_data_collator(features)"
   ],
   "id": "5d98d76eea149655",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:05.959787Z",
     "start_time": "2025-04-14T02:47:05.955239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = whole_word_masking_data_collator(samples)"
   ],
   "id": "dcd9a54da08b00a2",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:06.076047Z",
     "start_time": "2025-04-14T02:47:06.072319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for chunk in batch[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ],
   "id": "278469b20b3a5220",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] i [MASK] [MASK] [MASK] curious [MASK] yellow from my video store because of all the controversy that surrounded [MASK] when it was first released in 1967. i also heard that [MASK] [MASK] it [MASK] [MASK] by u [MASK] s. customs [MASK] it ever tried to enter this country, therefore being [MASK] fan of [MASK] [MASK] \" controversial \" [MASK] really had to [MASK] [MASK] [MASK] myself. < [MASK] / > < br / > the plot is centered around a young swedish drama student named [MASK] who [MASK] [MASK] learn everything she [MASK] about [MASK]. [MASK] particular she wants to focus her [MASK] [MASK] to making some sort of documentary on [MASK] the average [MASK] [MASK] thought about certain political issues such as the vietnam war [MASK] race issues in the united states. in between [MASK] [MASK] and [MASK] denizens of stockholm about their opinions on politics [MASK] she [MASK] sex with her drama teacher [MASK] classmates, and married men. < [MASK] / > < br / > [MASK] kills me about i [MASK] curious - yellow is that 40 years ago, this [MASK] considered pornographic. [MASK] [MASK] the sex and nudity scenes [MASK] few and far between, even then it ' s not shot like [MASK] cheaply made porno. while my countrymen mind find [MASK] shocking, in reality sex [MASK] nudity [MASK] a major staple [MASK] swedish [MASK] [MASK] [MASK] ingmar bergman [MASK] arguably [MASK] answer to good old boy [MASK] ford, [MASK] sex scenes in his films. < br / > < br [MASK] > i do commend the filmmakers for the fact [MASK] any sex shown in the [MASK] is shown for artistic purposes rather than [MASK] to shock [MASK] [MASK] make money to be shown in pornographic theaters in america. i am curious - yellow is a good film for anyone wanting to study the meat and potatoes ( no pun intended ) [MASK] swedish cinema. but really, this film doesn ' t have [MASK] [MASK] a plot. [SEP] [CLS] \" i am curious : yellow \" is a risible and pretentious steaming pile. [MASK] [MASK] ' t matter what one ' s political views are because [MASK] film [MASK] hardly be taken seriously [MASK] any [MASK]. as for the claim that frontal male nudity is an automatic [MASK] - 17, that isn ' t [MASK] [MASK] [MASK] [MASK] ve seen r - rated films with male nudity. granted, they only offer some fleeting views [MASK] but where are the r - rated [MASK] with gaping vulvas and flapping labia? nowhere, because they don ' t exist. the [MASK] [MASK] [MASK] those crappy [MASK] shows : schlongs swinging in the breeze but [MASK] a clitoris in sight [MASK] and those pretentious [MASK] movies like'\n",
      "\n",
      "'>>> [MASK] brown bunny, in [MASK] [MASK] ' re treated to the site [MASK] vincent gallo ' s [MASK] johnson, but [MASK] a trace of pink visible on chloe [MASK] [MASK] [MASK]. before crying ( or implying [MASK] [MASK] double - standard \" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference [MASK] men and women : there are no genitals [MASK] display when [MASK] appears nude, and the same cannot be said for a man. [MASK] fact, you generally won ' [MASK] see female genitals in an [MASK] film in anything short of porn or explicit erotica. this [MASK] double - standard is less a double standard than an admittedly [MASK] [MASK] ability to come to terms culturally [MASK] the [MASK] of [MASK] ' s bodies. [SEP] [CLS] if [MASK] [MASK] avoid [MASK] [MASK] type [MASK] film in the future [MASK] this film is interesting as an experiment but tells no [MASK] [MASK] [MASK]. < [MASK] / > < br / > one might feel virtuous for sitting [MASK] it [MASK] it [MASK] on so many important issues but it [MASK] so [MASK] any [MASK] [MASK] [MASK] motive. [MASK] viewer comes away with no new perspectives ( unless one comes up [MASK] [MASK] while one [MASK] s mind wanders [MASK] as it will invariably do during [MASK] pointless [MASK] [MASK]. [MASK] br / > < br / > one might better [MASK] [MASK] ' [MASK] time staring out [MASK] window at a tree growing. < br / > < br / > [SEP] [CLS] this film was probably inspired by godard [MASK] s masculin, feminin and i urge you to see that film [MASK]. < [MASK] / [MASK] < br / > the film has two [MASK] elements [MASK] those are, ( 1 ) the realistic acting ( 2 [MASK] [MASK] [MASK], undeservedly good, photo [MASK] apart from that, what strikes me most [MASK] the endless stream [MASK] [MASK] [MASK] [MASK]. lena nyman has [MASK] be most annoying actress in the [MASK]. she [MASK] so stupid and with all the nudity in this film,... it ' s [MASK] [MASK] [MASK]. comparing to godard ' s [MASK], intellectuality has been replaced with stupidity [MASK] without going too far [MASK] this subject, i would say [MASK] follows from the difference [MASK] [MASK] [MASK] the french and the swedish society. < br [MASK] > < br / > a movie of its [MASK], and [MASK] [MASK] 2 / 10. [SEP] [CLS] [MASK], brother... after hearing [MASK] this ridiculous film for [MASK] [MASK] [MASK] years all i can think of is that old [MASK] lee song [MASK] [MASK] < br / > < br / [MASK]'\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:06.189957Z",
     "start_time": "2025-04-14T02:47:06.188246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train_size = 10_000\n",
    "# test_size = int(0.1 * train_size)\n",
    "#\n",
    "# downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
    "#     train_size=train_size, test_size=test_size, seed=42\n",
    "# )\n",
    "# downsampled_dataset"
   ],
   "id": "12c7d2448195a720",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:09:24.659708Z",
     "start_time": "2025-04-14T03:09:24.651101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import notebook_login, accept_access_request\n",
    "\n",
    "notebook_login()"
   ],
   "id": "968460f59bc49881",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddcb80a289934846aa967de0e2b6de84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:06.727508Z",
     "start_time": "2025-04-14T02:47:06.412383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "# 在每个 epoch 输出训练的 loss\n",
    "logging_steps = len(lm_datasets[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"/data/wzq/cache/huggingface/hub/{model_name}-finetuned-imdb\",\n",
    "    overwrite_output_dir=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    push_to_hub=True,\n",
    "    fp16=True,\n",
    "    logging_steps=logging_steps,\n",
    ")"
   ],
   "id": "755e8b424322458e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wzq/miniconda3/envs/pytorch-nlp/lib/python3.12/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:07.210348Z",
     "start_time": "2025-04-14T02:47:06.795235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ],
   "id": "717f47f5d7ebe099",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2596270/2903405389.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:47:33.018737Z",
     "start_time": "2025-04-14T02:47:07.292844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ],
   "id": "691dcf624706170b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='468' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 01:59]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 19.26\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:52:00.324660Z",
     "start_time": "2025-04-14T02:47:48.655881Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.train()",
   "id": "61f45dc32da11153",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [720/720 03:56, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.493100</td>\n",
       "      <td>2.300219</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.397700</td>\n",
       "      <td>2.257361</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.361600</td>\n",
       "      <td>2.239156</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=720, training_loss=2.417264187335968, metrics={'train_runtime': 236.9259, 'train_samples_per_second': 193.896, 'train_steps_per_second': 3.039, 'total_flos': 6089726949894144.0, 'train_loss': 2.417264187335968, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:52:25.314332Z",
     "start_time": "2025-04-14T02:52:00.447261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ],
   "id": "60285ab4ea846540",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='234' max='234' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [234/234 00:24]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Perplexity: 9.39\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:52:37.959850Z",
     "start_time": "2025-04-14T02:52:31.737965Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.push_to_hub()",
   "id": "e9c39199c9b14640",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/KinomotoMio/distilbert-base-uncased-finetuned-imdb/commit/804b57b894a378d99ca77fabe37b8d16eaceffb2', commit_message='End of training', commit_description='', oid='804b57b894a378d99ca77fabe37b8d16eaceffb2', pr_url=None, repo_url=RepoUrl('https://hf-mirror.com/KinomotoMio/distilbert-base-uncased-finetuned-imdb', endpoint='https://hf-mirror.com', repo_type='model', repo_id='KinomotoMio/distilbert-base-uncased-finetuned-imdb'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:53:13.661081Z",
     "start_time": "2025-04-14T02:53:13.658141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def insert_random_mask(batch):\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    masked_inputs = data_collator(features)\n",
    "\n",
    "    return {\"masked_\" + k: v.numpy() for k, v in masked_inputs.items()}"
   ],
   "id": "a823243c412f79cf",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:53:51.458080Z",
     "start_time": "2025-04-14T02:53:40.462971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lm_datasets = lm_datasets.remove_columns([\"word_ids\"])\n",
    "eval_dataset = lm_datasets[\"test\"].map(\n",
    "    insert_random_mask,\n",
    "    batched=True,\n",
    "    remove_columns=lm_datasets[\"test\"].column_names,\n",
    ")\n",
    "eval_dataset = eval_dataset.rename_columns(\n",
    "    {\n",
    "        \"masked_input_ids\": \"input_ids\",\n",
    "        \"masked_attention_mask\": \"attention_mask\",\n",
    "        \"masked_labels\": \"labels\",\n",
    "    }\n",
    ")"
   ],
   "id": "8ab2b4b124d341",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/14966 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51b18e36d6564b99b3ddc1a71cde0bfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:55:11.584167Z",
     "start_time": "2025-04-14T02:55:11.580956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import default_data_collator\n",
    "\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(\n",
    "    lm_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=data_collator,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, batch_size=batch_size, collate_fn=default_data_collator\n",
    ")"
   ],
   "id": "90c4d79e393ff6e4",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:55:26.983071Z",
     "start_time": "2025-04-14T02:55:26.635944Z"
    }
   },
   "cell_type": "code",
   "source": "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)",
   "id": "190094733f92090e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:55:51.820913Z",
     "start_time": "2025-04-14T02:55:51.818039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ],
   "id": "fc290989d77535cd",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:57:04.834235Z",
     "start_time": "2025-04-14T02:57:04.778076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ],
   "id": "c03d1eec3fdc77ca",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T02:58:56.465888Z",
     "start_time": "2025-04-14T02:58:56.463018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ],
   "id": "bb3bde6df8cf737f",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:15:41.821266Z",
     "start_time": "2025-04-14T03:15:41.588030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import get_full_repo_name\n",
    "\n",
    "model_name = \"distilbert-base-uncased-finetuned-imdb-accelerate\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ],
   "id": "df7fe18ae4a3ec8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KinomotoMio/distilbert-base-uncased-finetuned-imdb-accelerate'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:17:48.761276Z",
     "start_time": "2025-04-14T03:17:48.243144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import create_repo\n",
    "\n",
    "create_repo(\n",
    "    repo_id=\"KinomotoMio/distilbert-base-uncased-finetuned-imdb-accelerate\",\n",
    "    repo_type=\"model\",\n",
    "    private=False,\n",
    "    exist_ok=True,\n",
    ")"
   ],
   "id": "c990e66fa74b41e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://hf-mirror.com/KinomotoMio/distilbert-base-uncased-finetuned-imdb-accelerate', endpoint='https://hf-mirror.com', repo_type='model', repo_id='KinomotoMio/distilbert-base-uncased-finetuned-imdb-accelerate')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:18:29.761628Z",
     "start_time": "2025-04-14T03:18:27.493302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "output_dir = \"/data/wzq/cache/huggingface/hub/\" + model_name\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ],
   "id": "fa49f91bfc5062ba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wzq/miniconda3/envs/pytorch-nlp/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://hf-mirror.com/KinomotoMio/distilbert-base-uncased-finetuned-imdb-accelerate into local empty directory.\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:26:34.487151Z",
     "start_time": "2025-04-14T03:22:27.821231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import math\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # 训练\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # 评估\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        losses.append(accelerator.gather(loss.repeat(batch_size)))\n",
    "\n",
    "    losses = torch.cat(losses)\n",
    "    losses = losses[: len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity = math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity = float(\"inf\")\n",
    "\n",
    "    print(f\">>> Epoch {epoch}: Perplexity: {perplexity}\")\n",
    "\n",
    "    # 保存并上传\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ],
   "id": "a7898084ea6165d1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/720 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45d98c7c511842db9b4950ff5ec8cecd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Epoch 0: Perplexity: 9.045098986018697\n",
      ">>> Epoch 1: Perplexity: 8.883463061453169\n",
      ">>> Epoch 2: Perplexity: 8.883463061453169\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:28:02.158331Z",
     "start_time": "2025-04-14T03:27:33.498108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", model=\"KinomotoMio/distilbert-base-uncased-finetuned-imdb-accelerate\"\n",
    ")"
   ],
   "id": "39b24b836bc97d5d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/338 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de0b4065c25f42dcbd70752e94483916"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60c3cb0da6ee4e9cb9202efa574f02fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9273a8ddeca045789b83512880386f33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c791f54ad0de4028a35277340d6746b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acf591e115eb46358dc728b28d0e7cb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3bd58f9b6b7478b9e2eac9999deb4ac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T03:28:05.169318Z",
     "start_time": "2025-04-14T03:28:05.122860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preds = mask_filler(text)\n",
    "\n",
    "for pred in preds:\n",
    "    print(f\">>> {pred['sequence']}\")"
   ],
   "id": "7d045e2fa34b5a65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> this is a great film.\n",
      ">>> this is a great movie.\n",
      ">>> this is a great idea.\n",
      ">>> this is a great adventure.\n",
      ">>> this is a great show.\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a14afa9e5e6d2d08"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
